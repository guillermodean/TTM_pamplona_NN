{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to install with pip tensorflow i had to change the registry value for longpaths.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.preprocessing import   LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento y exploracion de datos\n",
    "\n",
    "Leedmos el conjunto de datos que esta guardado en data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (45,46,63) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('data/Results_TTM.csv',sep=\";\",header=0)\n",
    "df=df.drop(columns=[\"Step status\",\"Current trend\",\"Torque rate min\",\"Torque rate max\",\"Torque rate trend\",\"CVILOGIX\",\"Identifier6\",\"Identifier7\",\"Identifier8\",\"Identifier9\",\"Identifier10\",\"Second transducer torque deviation\",\"Second transducer angle deviation\",\"Result type\",\"Pulse counter\",\"Angle offset\",\"AO torque rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.describe of        Result status Tool status  Result number            Time result  \\\n",
      "0                 OK          OK         613029  2020-12-10 23:59:12.0   \n",
      "1                 OK          OK         613028  2020-12-10 23:59:08.0   \n",
      "2                 OK          OK         613027  2020-12-10 23:58:56.0   \n",
      "3                 OK          OK         613026  2020-12-10 23:58:48.0   \n",
      "4                 OK          OK         613025  2020-12-10 23:58:41.0   \n",
      "...              ...         ...            ...                    ...   \n",
      "399995            OK          OK         286841  2020-09-29 18:51:08.0   \n",
      "399996            OK          OK         286840  2020-09-29 18:51:03.0   \n",
      "399997            OK          OK         760759  2020-09-29 18:50:45.0   \n",
      "399998            OK          OK         487287  2020-09-29 18:50:40.0   \n",
      "399999            OK          OK         356116  2020-09-29 18:50:37.0   \n",
      "\n",
      "        Pset ID  Step ID Error Code     Stop source  Torque min  Torque  ...  \\\n",
      "0          10.0      1.0        NaN  Target reached        18.0  20.126  ...   \n",
      "1           9.0      1.0        NaN  Target reached        18.0  20.090  ...   \n",
      "2           3.0      1.0        NaN  Target reached        20.0  22.219  ...   \n",
      "3           3.0      1.0        NaN  Target reached        20.0  22.138  ...   \n",
      "4           3.0      1.0        NaN  Target reached        20.0  22.073  ...   \n",
      "...         ...      ...        ...             ...         ...     ...  ...   \n",
      "399995      5.0      1.0        NaN  Target reached        20.0  22.422  ...   \n",
      "399996      5.0      1.0        NaN  Target reached        20.0  22.154  ...   \n",
      "399997     16.0      1.0        NaN  Target reached         8.0  10.049  ...   \n",
      "399998     21.0      1.0        NaN  Target reached         3.5   4.543  ...   \n",
      "399999     18.0      1.0        NaN  Target reached        35.0  37.966  ...   \n",
      "\n",
      "        Batch         Identifier1        Identifier2  Identifier3  \\\n",
      "0        1(0)                 NaN                NaN          NaN   \n",
      "1        1(0)                 NaN                NaN          NaN   \n",
      "2        1(0)                 NaN                NaN          NaN   \n",
      "3        1(0)                 NaN                NaN          NaN   \n",
      "4        1(0)                 NaN                NaN          NaN   \n",
      "...       ...                 ...                ...          ...   \n",
      "399995   2(2)  #######89161-05/00  552001922428000.0       2362.0   \n",
      "399996   1(2)  #######89161-05/00  552001922428000.0       2362.0   \n",
      "399997   1(0)                 NaN                NaN          NaN   \n",
      "399998   1(0)                 NaN                NaN          NaN   \n",
      "399999   1(0)                 NaN                NaN          NaN   \n",
      "\n",
      "        Identifier4 Identifier5  Torque (monitoring)  Angle (monitoring)  \\\n",
      "0               NaN         NaN                  ---                 ---   \n",
      "1               NaN         NaN                  ---                 ---   \n",
      "2               NaN         NaN                  ---                 ---   \n",
      "3               NaN         NaN                  ---                 ---   \n",
      "4               NaN         NaN                  ---                 ---   \n",
      "...             ...         ...                  ...                 ...   \n",
      "399995          NaN         NaN                  ---                 ---   \n",
      "399996          NaN         NaN                  ---                 ---   \n",
      "399997          NaN         NaN                  ---                 ---   \n",
      "399998          NaN         NaN                  ---                 ---   \n",
      "399999          NaN         NaN                  ---                 ---   \n",
      "\n",
      "        Controlling transducer  Angle Threshold   \n",
      "0                            0              10.0  \n",
      "1                            0              10.0  \n",
      "2                            0              11.0  \n",
      "3                            0              11.0  \n",
      "4                            0              11.0  \n",
      "...                        ...               ...  \n",
      "399995                       0               7.0  \n",
      "399996                       0               7.0  \n",
      "399997                       0               4.0  \n",
      "399998                       0               3.7  \n",
      "399999                       0              19.0  \n",
      "\n",
      "[400000 rows x 47 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(df.describe)\n",
    "df=df[['Result status','Result number','Time result','Pset ID','Step ID','Error Code', 'Torque min','Torque','Torque max','Angle min','Angle','Angle max','Pset name','VIN','Identifier1','Identifier2','Identifier3','Identifier4','Identifier5']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos quedamos con las columnas que tienen valores interesante y eliminamos todas las columnas que contienen muchos nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400000 entries, 0 to 399999\n",
      "Data columns (total 19 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   Result status  400000 non-null  object \n",
      " 1   Result number  400000 non-null  int64  \n",
      " 2   Time result    400000 non-null  object \n",
      " 3   Pset ID        399901 non-null  float64\n",
      " 4   Step ID        399901 non-null  float64\n",
      " 5   Error Code     22688 non-null   object \n",
      " 6   Torque min     399901 non-null  float64\n",
      " 7   Torque         400000 non-null  float64\n",
      " 8   Torque max     399901 non-null  float64\n",
      " 9   Angle min      399901 non-null  float64\n",
      " 10  Angle          400000 non-null  float64\n",
      " 11  Angle max      399901 non-null  float64\n",
      " 12  Pset name      399901 non-null  object \n",
      " 13  VIN            172013 non-null  object \n",
      " 14  Identifier1    172013 non-null  object \n",
      " 15  Identifier2    170608 non-null  object \n",
      " 16  Identifier3    168406 non-null  object \n",
      " 17  Identifier4    13920 non-null   object \n",
      " 18  Identifier5    12363 non-null   object \n",
      "dtypes: float64(8), int64(1), object(10)\n",
      "memory usage: 58.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenombramos las columnas para eliminar los espacios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.rename(columns={\"Result status\":\"Result_status\",\"Result number\":\"Result_number\",\"Pset ID\":\"Pset_ID\",\"Step ID\":\"Step_ID\",\"Torque min\":\"Torque_min\",\"Torque max\":\"Torque_max\",\"Angle min\":\"Angle_min\",\"Angle max\":\"Angle_max\",\"Pset name\":\"Pset_name\",'Error code':'Error_code','Result_status':'Result_status','Time result':'Time_result'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a mirar a ver cuales de los pares son NOK, filtramos la columna de resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22568 entries, 34 to 399969\n",
      "Data columns (total 19 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Result_status  22568 non-null  object \n",
      " 1   Result_number  22568 non-null  int64  \n",
      " 2   Time_result    22568 non-null  object \n",
      " 3   Pset_ID        22568 non-null  float64\n",
      " 4   Step_ID        22568 non-null  float64\n",
      " 5   Error Code     22568 non-null  object \n",
      " 6   Torque_min     22568 non-null  float64\n",
      " 7   Torque         22568 non-null  float64\n",
      " 8   Torque_max     22568 non-null  float64\n",
      " 9   Angle_min      22568 non-null  float64\n",
      " 10  Angle          22568 non-null  float64\n",
      " 11  Angle_max      22568 non-null  float64\n",
      " 12  Pset_name      22568 non-null  object \n",
      " 13  VIN            9477 non-null   object \n",
      " 14  Identifier1    9477 non-null   object \n",
      " 15  Identifier2    9289 non-null   object \n",
      " 16  Identifier3    9301 non-null   object \n",
      " 17  Identifier4    1431 non-null   object \n",
      " 18  Identifier5    1354 non-null   object \n",
      "dtypes: float64(8), int64(1), object(10)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_nok=df[df['Result_status'].str.contains(\"NOK\")]\n",
    "df_nok.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Result_status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pset_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Seat frame front_35Nm</th>\n",
       "      <td>1109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Armrests 28Nm</th>\n",
       "      <td>990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slides 22Nm TX40 ISC</th>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cross angle back - Swivel_22Nm</th>\n",
       "      <td>885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seat frame assy_35Nm_2x59-2_ISC</th>\n",
       "      <td>877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Backrest segment 22Nm ISC_A_BAU</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Poka Yoke Check_6xxx</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Torque_35Nm</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cross static support to slides 22Nm ISC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cushion slides_WOOD_10Nm+-2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Result_status\n",
       "Pset_name                                             \n",
       "Seat frame front_35Nm                             1109\n",
       "Armrests 28Nm                                      990\n",
       "Slides 22Nm TX40 ISC                               920\n",
       "Cross angle back - Swivel_22Nm                     885\n",
       "Seat frame assy_35Nm_2x59-2_ISC                    877\n",
       "...                                                ...\n",
       "Backrest segment 22Nm ISC_A_BAU                      1\n",
       "Poka Yoke Check_6xxx                                 1\n",
       "Torque_35Nm                                          1\n",
       "Cross static support to slides 22Nm ISC              1\n",
       "Cushion slides_WOOD_10Nm+-2                          1\n",
       "\n",
       "[208 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nok['Pset_name'].head()\n",
    "df_nok[['Pset_name','Result_status']].groupby(by='Pset_name').count().sort_values(by=['Result_status'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que hay un resultado POKA YOKE, es un resultado NOK forzado que se hace para comprobar la herramientas. hay que quitarlos de la muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df[\"Pset_name\"].str.contains(\"Poka\",na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos el tipo de la columna fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result_status                        object\n",
       "Result_number                         int64\n",
       "Time_result      datetime64[ns, US/Eastern]\n",
       "Pset_ID                             float64\n",
       "Step_ID                             float64\n",
       "Error Code                           object\n",
       "Torque_min                          float64\n",
       "Torque                              float64\n",
       "Torque_max                          float64\n",
       "Angle_min                           float64\n",
       "Angle                               float64\n",
       "Angle_max                           float64\n",
       "Pset_name                            object\n",
       "VIN                                  object\n",
       "Identifier1                          object\n",
       "Identifier2                          object\n",
       "Identifier3                          object\n",
       "Identifier4                          object\n",
       "Identifier5                          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.astype({'Time_result': 'datetime64[ns, US/Eastern]'}).dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creamos una columna nueva la columna de resultado que contiene los tesxtos \"NOK\" y \"OK\" en valores numericos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Resultbin']=df['Result_status']=='OK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Result_status</th>\n",
       "      <th>Result_number</th>\n",
       "      <th>Time_result</th>\n",
       "      <th>Pset_ID</th>\n",
       "      <th>Step_ID</th>\n",
       "      <th>Error Code</th>\n",
       "      <th>Torque_min</th>\n",
       "      <th>Torque</th>\n",
       "      <th>Torque_max</th>\n",
       "      <th>Angle_min</th>\n",
       "      <th>Angle</th>\n",
       "      <th>Angle_max</th>\n",
       "      <th>Pset_name</th>\n",
       "      <th>VIN</th>\n",
       "      <th>Identifier1</th>\n",
       "      <th>Identifier2</th>\n",
       "      <th>Identifier3</th>\n",
       "      <th>Identifier4</th>\n",
       "      <th>Identifier5</th>\n",
       "      <th>Resultbin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OK</td>\n",
       "      <td>613029</td>\n",
       "      <td>2020-12-10 23:59:12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.126</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40.213</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Fixation screw_(60895R01)_20Nm_1x64-5_IF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK</td>\n",
       "      <td>613028</td>\n",
       "      <td>2020-12-10 23:59:08.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.090</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>40.369</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Fixation screw_(318327B01)_20Nm_1x64-4_I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OK</td>\n",
       "      <td>613027</td>\n",
       "      <td>2020-12-10 23:58:56.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.219</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>40.389</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Sliders 22Nm_4x65-4_ISC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OK</td>\n",
       "      <td>613026</td>\n",
       "      <td>2020-12-10 23:58:48.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.138</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>33.650</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Sliders 22Nm_4x65-4_ISC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>613025</td>\n",
       "      <td>2020-12-10 23:58:41.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.073</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>43.830</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Sliders 22Nm_4x65-4_ISC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Result_status  Result_number            Time_result  Pset_ID  Step_ID  \\\n",
       "0            OK         613029  2020-12-10 23:59:12.0     10.0      1.0   \n",
       "1            OK         613028  2020-12-10 23:59:08.0      9.0      1.0   \n",
       "2            OK         613027  2020-12-10 23:58:56.0      3.0      1.0   \n",
       "3            OK         613026  2020-12-10 23:58:48.0      3.0      1.0   \n",
       "4            OK         613025  2020-12-10 23:58:41.0      3.0      1.0   \n",
       "\n",
       "  Error Code  Torque_min  Torque  Torque_max  Angle_min   Angle  Angle_max  \\\n",
       "0        NaN        18.0  20.126        22.0        3.0  40.213      100.0   \n",
       "1        NaN        18.0  20.090        22.0        5.0  40.369      100.0   \n",
       "2        NaN        20.0  22.219        24.0        5.0  40.389      110.0   \n",
       "3        NaN        20.0  22.138        24.0        5.0  33.650      110.0   \n",
       "4        NaN        20.0  22.073        24.0        5.0  43.830      110.0   \n",
       "\n",
       "                                  Pset_name  VIN Identifier1 Identifier2  \\\n",
       "0  Fixation screw_(60895R01)_20Nm_1x64-5_IF  NaN         NaN         NaN   \n",
       "1  Fixation screw_(318327B01)_20Nm_1x64-4_I  NaN         NaN         NaN   \n",
       "2                   Sliders 22Nm_4x65-4_ISC  NaN         NaN         NaN   \n",
       "3                   Sliders 22Nm_4x65-4_ISC  NaN         NaN         NaN   \n",
       "4                   Sliders 22Nm_4x65-4_ISC  NaN         NaN         NaN   \n",
       "\n",
       "  Identifier3 Identifier4 Identifier5  Resultbin  \n",
       "0         NaN         NaN         NaN       True  \n",
       "1         NaN         NaN         NaN       True  \n",
       "2         NaN         NaN         NaN       True  \n",
       "3         NaN         NaN         NaN       True  \n",
       "4         NaN         NaN         NaN       True  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aun tenemos columnas que no van a aportar nada a nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX=df.drop(columns={'Result_status','Result_number','Time_result','Pset_ID','Identifier4','Identifier5','Identifier2','Error Code','Torque','Angle'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "con df.info() vamos a ver cuantas columnas contienen resultados nulos y vamos a hacer que toda la muestra tenga columnas con datos que podamos utilizar.\n",
    "Con esta accion podemos hacer que nuestro modelo posterior no sea tan bueno prediciendo los resultados de las columnas que tienen nulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 398943 entries, 0 to 399999\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   Step_ID      398844 non-null  float64\n",
      " 1   Torque_min   398844 non-null  float64\n",
      " 2   Torque_max   398844 non-null  float64\n",
      " 3   Angle_min    398844 non-null  float64\n",
      " 4   Angle_max    398844 non-null  float64\n",
      " 5   Pset_name    398844 non-null  object \n",
      " 6   VIN          172013 non-null  object \n",
      " 7   Identifier1  172013 non-null  object \n",
      " 8   Identifier3  168406 non-null  object \n",
      " 9   Resultbin    398943 non-null  bool   \n",
      "dtypes: bool(1), float64(5), object(4)\n",
      "memory usage: 30.8+ MB\n"
     ]
    }
   ],
   "source": [
    "dfX.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a echar un vistazo a los valores que vamos a quitar. porque se va a reducir mucho la muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1599: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = infer_fill_value(value)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resultbin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pset_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sliders 22Nm_4x65-4_ISC</th>\n",
       "      <td>19342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Backrest_40Nm</th>\n",
       "      <td>10887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seat frame assy_35Nm_2x59-2_ISC</th>\n",
       "      <td>10709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bearing inclination cap_22Nm_2x59-1_ISC</th>\n",
       "      <td>10022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inner carrier_22Nm_2x59-3_ISC</th>\n",
       "      <td>9927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cushion slides_WOOD_10Nm+-2</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embocar Profiles 30Nm ISC</th>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slides 22Nm TX40 ISC</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Torque 35Nm</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inner carrier 22Nm HEX8 ISC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Resultbin\n",
       "Pset_name                                         \n",
       "Sliders 22Nm_4x65-4_ISC                      19342\n",
       "Backrest_40Nm                                10887\n",
       "Seat frame assy_35Nm_2x59-2_ISC              10709\n",
       "Bearing inclination cap_22Nm_2x59-1_ISC      10022\n",
       "Inner carrier_22Nm_2x59-3_ISC                 9927\n",
       "...                                            ...\n",
       "Cushion slides_WOOD_10Nm+-2                     80\n",
       "Embocar Profiles 30Nm ISC                       77\n",
       "Slides 22Nm TX40 ISC                             6\n",
       "Torque 35Nm                                      4\n",
       "Inner carrier 22Nm HEX8 ISC                      1\n",
       "\n",
       "[61 rows x 1 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_NANs=dfX[['Pset_name','Identifier1','Identifier3','Resultbin']]\n",
    "df_NANs.loc[df_NANs['Identifier1'].isnull(),'value_is_NaN'] = 'Yes'\n",
    "df_NANs.loc[df_NANs['Identifier1'].notnull(), 'value_is_NaN'] = 'No'\n",
    "df_NANs = df_NANs[df_NANs[\"value_is_NaN\"].str.contains(\"Yes\",na=False)]\n",
    "df_NANs[['Pset_name','Resultbin']].groupby(by='Pset_name').count().sort_values(by='Resultbin',ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos perdiendo valores OK y NOK de las líneas NTS1 y NTS2 que no guardan valueIdentifiers. Es decir que el analisis se va a focalizar en las líneas:\n",
    "1. ALter BAU\n",
    "2. Alter BUS\n",
    "3. Tapizado NTS1\n",
    "4. Tapizado NTS2\n",
    "5. NTS1 BAU\n",
    "Vamos a proceder a eliminar los resultados nulos del Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 168002 entries, 10 to 399996\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   Step_ID      168002 non-null  float64\n",
      " 1   Torque_min   168002 non-null  float64\n",
      " 2   Torque_max   168002 non-null  float64\n",
      " 3   Angle_min    168002 non-null  float64\n",
      " 4   Angle_max    168002 non-null  float64\n",
      " 5   Pset_name    168002 non-null  object \n",
      " 6   VIN          168002 non-null  object \n",
      " 7   Identifier1  168002 non-null  object \n",
      " 8   Identifier3  168002 non-null  object \n",
      " 9   Resultbin    168002 non-null  bool   \n",
      "dtypes: bool(1), float64(5), object(4)\n",
      "memory usage: 13.0+ MB\n"
     ]
    }
   ],
   "source": [
    "dfX=dfX.dropna()\n",
    "dfX = dfX[pd.to_numeric(dfX['Identifier3'],errors='coerce').notna()]\n",
    "dfX.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos ahora que tenemos 168.002 registros no nulos con los que podemos elaborar un modelo. vamos a ver el porcentaje de aprietes NOK totales.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Step_ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resultbin</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>9236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>158766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Step_ID\n",
       "Resultbin         \n",
       "False         9236\n",
       "True        158766"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfX[['Resultbin','Step_ID']].groupby(by='Resultbin').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05391998355654818"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OKS = len(df[df[\"Result_status\"].str.contains(\"OK\",na=False)])\n",
    "NOKS=len(df[df[\"Result_status\"].str.contains(\"NOK\",na=False)])\n",
    "NOKS/OKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos un 5% de pares malos en este conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vamos a quitar algunos ok para que los modelos aprendan mejor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfX = dfX.drop(dfX[dfX['Resultbin'] == True].sample(frac=.6, random_state=101).index)\n",
    "#Quito el 40 % de los resultados OK  de DFX\n",
    "dfX_plot=dfX[['Resultbin','Step_ID']].groupby(by='Resultbin').count()\n",
    "ax = dfX_plot.plot.bar(y='Step_ID',rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05391998355654818"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OKS = len(df[df[\"Result_status\"].str.contains(\"OK\",na=False)])\n",
    "NOKS=len(df[df[\"Result_status\"].str.contains(\"NOK\",na=False)])\n",
    "NOKS/OKS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc=LabelEncoder()\n",
    "dfX=df[['Torque_min','Torque_max','Angle_min','Angle_max','Pset_name',\t'Identifier1','Identifier3','Resultbin']].dropna()\n",
    "dfX = dfX.drop(dfX[dfX['Resultbin'] == True].sample(frac=.4, random_state=101).index)\n",
    "#Quito el 40 % de los resultados OK  de DFX\n",
    "\n",
    "dfX['Identifier3'] = df['Identifier3'].astype('string',copy=False)\n",
    "dfX['Pset_name_cat'] = enc.fit_transform(dfX['Pset_name'])\n",
    "dfX['Modelo'] = enc.fit_transform(dfX['Identifier1'])\n",
    "dfX[['Identifier3','Resultbin']].groupby(by=\"Identifier3\").count()\n",
    "dfX[dfX['Identifier3'].apply(lambda x: x.isnumeric())]\n",
    "dfX['Trabajador'] = enc.fit_transform(dfX['Identifier3'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resultbin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identifier3</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1234.0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412.0</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505.0</th>\n",
       "      <td>2206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072.0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6000</th>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6000.0</th>\n",
       "      <td>636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9385.0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9472.0</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y000</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Resultbin\n",
       "Identifier3           \n",
       "1234.0               2\n",
       "1412.0              45\n",
       "1505                12\n",
       "1505.0            2206\n",
       "2072.0               6\n",
       "...                ...\n",
       "6000               134\n",
       "6000.0             636\n",
       "9385.0               2\n",
       "9472.0               8\n",
       "Y000                 3\n",
       "\n",
       "[115 rows x 1 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfX[['Identifier3','Resultbin']].groupby(by=\"Identifier3\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pset_name_cat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resultbin</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>9236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>95271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Pset_name_cat\n",
       "Resultbin               \n",
       "False               9236\n",
       "True               95271"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfX[['Resultbin','Pset_name_cat']].groupby(by='Resultbin').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 104507 entries, 17 to 399996\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   Torque_min     104507 non-null  float64\n",
      " 1   Torque_max     104507 non-null  float64\n",
      " 2   Angle_min      104507 non-null  float64\n",
      " 3   Angle_max      104507 non-null  float64\n",
      " 4   Pset_name      104507 non-null  object \n",
      " 5   Identifier1    104507 non-null  object \n",
      " 6   Identifier3    104507 non-null  string \n",
      " 7   Resultbin      104507 non-null  bool   \n",
      " 8   Pset_name_cat  104507 non-null  int32  \n",
      " 9   Modelo         104507 non-null  int32  \n",
      " 10  Trabajador     104507 non-null  int32  \n",
      "dtypes: bool(1), float64(4), int32(3), object(2), string(1)\n",
      "memory usage: 7.7+ MB\n"
     ]
    }
   ],
   "source": [
    "dfX.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, ahora vamos a dejar el df solo con las columnas que nos interesan y empezaremos a preparar nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1] [[  7.  13.   0. ...  19. 115.  45.]\n",
      " [ 20.  22.   0. ...  73. 306.  73.]\n",
      " [ 20.  24.   0. ...  21. 306.  73.]\n",
      " ...\n",
      " [ 30.  40.   0. ...  27.  41.  89.]\n",
      " [ 20.  24.   0. ...  21.  41.  42.]\n",
      " [ 20.  24.   0. ...  21.  41.  42.]]\n"
     ]
    }
   ],
   "source": [
    "dfX[\"Resultbin\"] = dfX[\"Resultbin\"].astype(int)\n",
    "y=np.array(dfX[\"Resultbin\"])\n",
    "dfX=dfX.drop(columns={'Resultbin','Pset_name','Identifier1','Identifier3'})\n",
    "X=dfX.values\n",
    "print(y, X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs available: 1\n",
      "(104507,) (104507, 7)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy, BinaryCrossentropy\n",
    "from sklearn.utils import shuffle\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs available:\", len(physical_devices))\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "label=np.array(y)\n",
    "sample=np.array(X)\n",
    "\n",
    "print(label.shape,sample.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "label,sample =shuffle(label,sample)\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_samples= scaler.fit_transform(sample) #fit transform does not accept 1D data so we reshape the scaled train samples to be 2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# sns.pairplot (dfX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1] [[  7.  13.   0. ...  19. 115.  45.]\n",
      " [ 20.  22.   0. ...  73. 306.  73.]\n",
      " [ 20.  24.   0. ...  21. 306.  73.]\n",
      " ...\n",
      " [ 30.  40.   0. ...  27.  41.  89.]\n",
      " [ 20.  24.   0. ...  21.  41.  42.]\n",
      " [ 20.  24.   0. ...  21.  41.  42.]]\n",
      "(104507,) (104507, 7)\n"
     ]
    }
   ],
   "source": [
    "print(y, X)\n",
    "print(y.shape,X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1] [[0.5        0.475      0.         ... 0.15789474 0.23870968 0.79824561]\n",
      " [0.5        0.475      0.         ... 0.72932331 0.32580645 0.57894737]\n",
      " [0.5        0.475      0.         ... 0.80451128 0.27096774 0.39473684]\n",
      " ...\n",
      " [0.5        0.475      0.         ... 0.0075188  0.46774194 0.36842105]\n",
      " [0.5        0.475      0.         ... 0.80451128 0.28709677 0.37719298]\n",
      " [0.5        0.425      0.         ... 0.30827068 0.26451613 0.85964912]]\n",
      "(104507,) (104507, 7)\n"
     ]
    }
   ],
   "source": [
    "print(label,scaled_samples)\n",
    "print(label.shape,scaled_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_samples, label, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34488, 7) (70019, 7)\n",
      "(34488,) (70019,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape, X_train.shape)\n",
    "print(y_test.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-9f9df6710fcf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m METRICS = [\n\u001b[1;32m----> 2\u001b[1;33m       \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTruePositives\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m       \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFalsePositives\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'fp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m       \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrueNegatives\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tn'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m       \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFalseNegatives\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'fn'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.TruePositives(name='tp'),\n",
    "      tf.keras.metrics.FalsePositives(name='fp'),\n",
    "      tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "      tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),\n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "      tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprender métricas útiles\n",
    "\n",
    "Tenga en cuenta que hay algunas métricas definidas anteriormente que pueden ser calculadas por el modelo y que serán útiles al evaluar el desempeño.\n",
    "\n",
    "* Los falsos negativos y falsos positivos son muestras que fueron clasificadas incorrectamente.\n",
    "\n",
    "* Verdaderos negativos y positivos verdaderos son muestras que fueron clasificados correctamente.\n",
    "\n",
    "* La precisión es el porcentaje de ejemplos correctamente clasificada.\n",
    "\n",
    "* La precisión es el porcentaje de positivos predichos que se clasifican correctamente.\n",
    "\n",
    "* Recall es el porcentaje de positivos reales que fueron clasificados correctamente.\n",
    "\n",
    "* AUC se refiere al área bajo la curva de una curva característica de funcionamiento del receptor (ROC-AUC). Esta métrica es igual a la probabilidad de que un clasificador clasifique una muestra positiva aleatoria por encima de una muestra negativa aleatoria.\n",
    "\n",
    "* AUPRC se refiere al área bajo la curva de la curva de precisión de recordar. Esta métrica calcula pares de recuperación de precisión para diferentes umbrales de probabilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(metrics=METRICS,output_bias=None):\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(units=16,input_shape=[len(dfX.keys())],activation='relu'),\n",
    "        Dense(units=32,activation='relu'),\n",
    "        Dense(units=32,activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(units=2,activation='sigmoid',bias_initializer=output_bias)  # dos clases, par ok par nok.\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    # voy a cambiar el optimizer a ver si mejora \n",
    "    # from tensorflow.keras.optimizers import SGD\n",
    "    # from tensorflow.keras.metrics import categorical_crossentropy\n",
    "    # opt = SGD(learning_rate=0.01)\n",
    "    # model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = opt, metrics= ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_prc', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Tune model with keras tuner\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "  model = tf.keras.Sequential()\n",
    "\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  \n",
    "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "\n",
    "  model.add(tf.keras.layers.Dense(units=16,input_shape=[len(dfX.keys())],activation='relu'))\n",
    "  model.add(tf.keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "  model.add(tf.keras.layers.Dense(units=hp_units, activation='relu')) #added one layer more\n",
    "  model.add(tf.keras.layers.Dense(units=2,activation='sigmoid'))  #changed to sigmoid => is equivalent to softmax for two outputs\n",
    "\n",
    "  # Tune the learning rate for the optimizer\n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner.search(X_train, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# # Get the optimal hyperparameters\n",
    "# best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# print(f\"\"\"\n",
    "# The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "# layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "# is {best_hps.get('learning_rate')}.\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_train, y_train, batch_size=10, verbose=0)\n",
    "print(\"Loss: {:0.4f}\".format(results[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=X_train,y=y_train, validation_split=0.1,batch_size=10,epochs=10,shuffle=True, verbose=2)\n",
    "\n",
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "\n",
    "# model = tuner.hypermodel.build(best_hps)\n",
    "# history = model.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "# val_acc_per_epoch = history.history['val_accuracy']\n",
    "# best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "# print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto me va a decir cual es el best epoch, reentreno el modelo definiendo el best epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model\n",
    "\n",
    "\n",
    "# hypermodel = tuner.hypermodel.build(best_hps)\n",
    "# hypermodel.fit(X_train, y_train, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions and confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precictions=model.predict(x=X_test.tolist(),batch_size=10,verbose=0)\n",
    "print(precictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_predictions=np.argmax(precictions,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import  itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cm = confusion_matrix(y_true=y_test,y_pred=rounded_predictions)\n",
    "cm_plot_labels=['no OK','OK']\n",
    "plot_confusion_matrix (cm,cm_plot_labels,title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Me pasa lo mismo que con el modelo de regresion lineal => hay que tratar los datos para incrementar el numero de resultados NOK porcentualmente sobre el total de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrix logistic regresion in TTM_Pamplona\n",
    "\n",
    "[   12,  2308]\n",
    "\n",
    "\n",
    "[    0, 39686]\n",
    "con todo el dataframe  Neural Network % nok predicted good = 0,005\n",
    "tras reducir el número de pares Ok un 40% me sale la siguiente cm: Neural Network % nok predicted good 0.027\n",
    "\n",
    "[   80  2905]\n",
    "\n",
    "\n",
    "[    0 52462]\n",
    "\n",
    "quitando el angulo minimo. Neural Network % nok predicted good: 0.017\n",
    "\n",
    "[   53  3039]\n",
    "\n",
    "\n",
    "[    0 52355]\n",
    "\n",
    "vamos a volver a añadir  los pares ok a ver que hace but still i am too far\n",
    "\n",
    "con el 60% de los pares ok quitados: Neural Network % nok predicted NOK: 0.016\n",
    "\n",
    "[   48  3026]\n",
    "\n",
    "\n",
    "[    0 52373]\n",
    "\n",
    "vuelvo a poner el angulo mímimo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porcentaje_pares_LR=12/(12+2308)\n",
    "porcentaje_pares_NN=cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "\n",
    "print(\"Logistic regresion % nok predicted as NOK: \"+str(round(porcentaje_pares_LR,3)))\n",
    "print(\"Neural Network % nok predicted NOK: \"+str(round(porcentaje_pares_NN,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Use weight regularization.** It tries to keep weights low which very often leads to better generalization. Experiment with different regularization coefficients. Try 0.1, 0.01, 0.001 and see what impact they have on accuracy.\n",
    "\n",
    "\n",
    "2. **Corrupt your input** (e.g., randomly substitute some pixels with black or white). This way you remove information from your input and 'force' the network to pick up on important general features. Experiment with noising coefficients which determines how much of your input should be corrupted. Research shows that anything in the range of 15% - 45% works well.\n",
    "\n",
    "\n",
    "3. **Expand your training set.** Since you're dealing with images you can expand your set by rotating / scaling etc. your existing images (as suggested). You could also experiment with pre-processing your images (e.g., mapping them to black and white, grayscale etc. but the effectiveness of this technique will depend on your exact images and classes)\n",
    "\n",
    "\n",
    "4. **Pre-train your layers with denoising critera.** Here you pre-train each layer of your network individually before fine tuning the entire network. Pre-training 'forces' layers to pick up on important general features that are useful for reconstructing the input signal. Look into auto-encoders for example (they've been applied to image classification in the past).\n",
    "\n",
    "\n",
    "5. **Experiment with network architecture.** Your network might not have sufficient learning capacity. Experiment with different neuron types, number of layers, and number of hidden neurons. Make sure to try compressing architectures (less neurons than inputs) and sparse architectures (more neurons than inputs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. reducir aun mas los ok => cuanto mas?\n",
    "\n",
    "2. meter mas layers => done\n",
    "\n",
    "3. cambiar de softmax a sigmoid => done\n",
    "\n",
    "4. tune hiper parameters => done\n",
    "\n",
    "5. Ampliar el dataset con más NOK results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest clasifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_rf = rf.predict(X_train)\n",
    "\n",
    "print( np.unique( prediction_rf ) )\n",
    "\n",
    "print( accuracy_score(y_train, prediction_rf) )\n",
    "\n",
    " \n",
    "\n",
    "prob_y_4 = rf.predict_proba(X_train)\n",
    "prob_y_4 = [p[1] for p in prob_y_4]\n",
    "print( roc_auc_score(y_train, prob_y_4) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parece que estamos en las mismas..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_rf_test=rf.predict(X_test)\n",
    "cm_rf = confusion_matrix(y_true=y_test,y_pred=prediction_rf_test)\n",
    "cm_plot_labels_rf=['no OK','OK']\n",
    "plot_confusion_matrix (cm_rf,cm_plot_labels_rf,title='Confusion matrix Random forest clasifier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = rf.estimators_[5]\n",
    "feature_names=[]\n",
    "for col in dfX.columns:\n",
    "    feature_names.append(col)\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "# Export as dot file\n",
    "export_graphviz(estimator, out_file='tree.dot', \n",
    "                feature_names = feature_names,\n",
    "                class_names = feature_names,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "# Convert to png using system command (requires Graphviz)\n",
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'],shell=False)\n",
    "\n",
    "# Find the image on src"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1275a05ae34f0c315803f9d1758b76ed30a4d7265e5e486823be65aff6a6df27"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
